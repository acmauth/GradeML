{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple ML - Testing simple models#\n",
    "\n",
    "What it does?\n",
    "- Reads the csv file created by the Statistics Parser\n",
    "- Drops the string columns and keeps only the columns with the grades\n",
    "- Tests a model for each course-column using the LeaveOneOut method and the XGBoost Regressor\n",
    "- Prints the results in terms of MAE and RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_absolute_error,mean_squared_error\n",
    "import math\n",
    "\n",
    "import warnings #needed for this type of classifier\n",
    "warnings.simplefilter(action='ignore', category=Warning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"csd_2021.csv\")\n",
    "display(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "data.describe()\r\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rename Columns ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change Courses Names\n",
    "import json\n",
    "from pandas.io.json import json_normalize\n",
    "\n",
    "with open(\"courses_ids_600000014.json\",\"r\") as json_file:\n",
    "     json_file = json.load(json_file)\n",
    "coded_courses = json_normalize(json_file['courses'])\n",
    "del coded_courses['ccoursecode']\n",
    "course_dict = coded_courses.set_index('coursecode')['courseId'].to_dict()\n",
    "#display(course_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.rename(columns={\"Ηλικία\":\"age\",\"Φύλο\":\"gender\",\"Επέλεξα τη σχολή μου διότι:\":\"reason\",\n",
    "                     \"Κατά μέσο όρο την εβδομάδα, διαβάζω:\":\"study_time\",\n",
    "                    \"Μέσα στο εξάμηνο, παρακαλουθώ:\":\"lectures\",\n",
    "                     \"Υπήρξε ανάγκη για φροντηστηριακή βοήθεια σε κάποιο μάθημα έως τώρα;\":\"private\",\n",
    "                    \"Μετά το πτυχίο, θα ήθελα να ακολουθήσω:\":\"postgraduate\",\n",
    "                    \"Ποιο από τα παρακάτω ισχύει;\":\"roomates\",\n",
    "                    \"Η σχολή απέχει από το σπίτι μου:\":\"distance\",\n",
    "                    \"Ασχολούμαι εβδομαδιαία με:\":\"hobbies\"},inplace=True)\n",
    "for key in course_dict.keys():\n",
    "    data.rename(columns = {key:str(course_dict[key]).strip()}, inplace=True)\n",
    "display(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical Values Handling - Function ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "\n",
    "def handle_categorical(data):\n",
    "    \n",
    "    # Let's split to characteristics and courses\n",
    "    data_characteristics = data.iloc[:,:10]\n",
    "    data_courses = data.iloc[:,10:]\n",
    "\n",
    "    \n",
    "    # Categorical values that maintain the scaling properties \"study_time\",\"lectures\",\"postgraduate\",\"distance\"\n",
    "    # Study_time\n",
    "    data_characteristics[\"study_time\"] = data_characteristics[\"study_time\"].replace({\"0 - 2 ώρες\":0.0,\"2 - 5 ώρες\":1.0,\"> 5 ώρες\":2.0})\n",
    "    data_characteristics[\"study_time\"] = pd.to_numeric(data_characteristics[\"study_time\"])\n",
    "\n",
    "    # Lectures\n",
    "    data_characteristics[\"lectures\"] = data_characteristics[\"lectures\"].replace({\"Λιγότερες από τις μισές διαλέξεις\":0.0,\n",
    "                                                 \"Περίπου τις μισές διαλέξεις\":1.0,\n",
    "                                                 \"Παραπάνω από τις μισές διαλέξεις\":2.0,\n",
    "                                                 \"Όλες τις διαλέξεις\":3.0})\n",
    "    data_characteristics[\"lectures\"] = pd.to_numeric(data_characteristics[\"lectures\"])\n",
    "\n",
    "    # Postgraduate\n",
    "    data_characteristics[\"postgraduate\"] = data_characteristics[\"postgraduate\"].replace({\"Τίποτα από τα δύο\":0.0,\n",
    "                                                         \"Μεταπτυχιακές Σπούδες\":1.0,\n",
    "                                                         \"Διδακτορικές Σπουδές\":2.0})\n",
    "    data_characteristics[\"postgraduate\"] = pd.to_numeric(data_characteristics[\"postgraduate\"])\n",
    "\n",
    "    # Distance\n",
    "    data_characteristics[\"distance\"] = data_characteristics[\"distance\"].replace({\"< 10 λεπτά\":0.0,\n",
    "                                                 \"10 - 25 λεπτά\":1.0,\n",
    "                                                 \"25 - 45 λεπτά\":2.0,\n",
    "                                                 \"> 45 λεπτά\":3.0})\n",
    "    data_characteristics[\"distance\"] = pd.to_numeric(data_characteristics[\"distance\"])\n",
    "\n",
    "    # Gender\n",
    "    data_characteristics[\"gender\"] = data_characteristics[\"gender\"].replace({\"Κορίτσι\":1,\"Αγόρι\":0})\n",
    "    data_characteristics[\"gender\"] = pd.to_numeric(data_characteristics[\"gender\"])\n",
    "\n",
    "    # private\n",
    "    data_characteristics[\"private\"] = data_characteristics[\"private\"].replace({\"Ναι\":0,\n",
    "                                              \"Όχι\":1})\n",
    "    data_characteristics[\"private\"] = pd.to_numeric(data_characteristics[\"private\"])\n",
    "    \n",
    "    \n",
    "    # One-hot encoder columns (only roomates)\n",
    "\n",
    "    ohe_columns = [\"roomates\"]\n",
    "\n",
    "    full_pipeline = ColumnTransformer([\n",
    "        ('one_hot',OneHotEncoder(),ohe_columns)\n",
    "    ])\n",
    "\n",
    "    roomates = full_pipeline.fit_transform(data_characteristics)\n",
    "    # Concat with  data_characteristics with roomates\n",
    "    roomates_df = pd.DataFrame(roomates.toarray(),columns=['family','alone','friend','siblings'],dtype=np.int8)\n",
    "    data_characteristics_updated = pd.concat([data_characteristics.drop(\"roomates\",axis=1),roomates_df],axis=1)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Convert string cell with multiple values to list\n",
    "    acceptable_hobbies = [\"Σειρές / Ταινίες\",\"Αθλητισμό\",\"Video Games\",\"Ξένη γλώσσα\",\"Εθελοντισμός\"]\n",
    "    for student in range(0,data_characteristics.shape[0]):\n",
    "        data_characteristics['reason'][student] = data_characteristics['reason'][student].split(\", \") #There is a space after each comma\n",
    "        # Hobbies transformation\n",
    "\n",
    "        hobbies_list = data_characteristics['hobbies'][student].split(\", \")\n",
    "        for i in range(0,len(hobbies_list)):\n",
    "            if hobbies_list[i] not in acceptable_hobbies:\n",
    "                hobbies_list[i] = \"Άλλο\"\n",
    "        data_characteristics['hobbies'][student] = hobbies_list\n",
    "        \n",
    "        \n",
    "        # Multilabel Binarizer\n",
    "\n",
    "        mlb = MultiLabelBinarizer()\n",
    "        hobbies = mlb.fit_transform(data_characteristics['hobbies'])\n",
    "#         print(mlb.classes_)\n",
    "        reasons = mlb.fit_transform(data_characteristics['reason'])\n",
    "#         print(mlb.classes_)\n",
    "\n",
    "    # Convert to data_characteristics frame and concat\n",
    "    hobbies_df = pd.DataFrame(hobbies,columns=[\"vgames\",\"other\",\"sports\",\"volunteer\",\"languange\",\"movies\"])\n",
    "    data_characteristics_updated = pd.concat([data_characteristics_updated.drop([\"hobbies\"],axis=1),hobbies_df],axis=1)\n",
    "\n",
    "    reasons_df = pd.DataFrame(reasons,columns=[\"quality\",\"choice\",\"subject\",\"parents\",\"career\"])\n",
    "    data_characteristics_updated = pd.concat([data_characteristics_updated.drop([\"reason\"],axis=1),reasons_df],axis=1)\n",
    "    \n",
    "    full_data = pd.concat([data_characteristics_updated,data_courses],axis=1)\n",
    "    \n",
    "    return full_data, data_characteristics_updated.columns, data_courses.columns\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Handle Categorical ###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_updated, characteristics_cols, courses_cols = handle_categorical(data)\n",
    "display(characteristics_cols)\n",
    "display(courses_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating dictionary with courses as keys and number of students that passed the subject as values ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dict = {new_list: [] for new_list in range(0)}\n",
    "totalSum = 0\n",
    "iterations = 0 \n",
    "for column in courses_cols:\n",
    "    temp = data_updated[data_updated[column]> -1].shape[0]\n",
    "    if temp!=0:\n",
    "        totalSum = totalSum + temp\n",
    "        iterations = iterations + 1\n",
    "    new_dict[column] = temp\n",
    "mean = totalSum/iterations\n",
    "print(mean)\n",
    "print(new_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#List with only the courses we are going to use for the model\n",
    "alist = []\n",
    "for key in new_dict.keys():\n",
    "    if new_dict[key] > 10:\n",
    "        alist.append(key)\n",
    "display(alist)\n",
    "print(\"length:\",len(alist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select those course columns\n",
    "course_columns = alist\n",
    "print(course_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use all courses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting all courses\n",
    "course_columns = courses_cols\n",
    "print(course_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Only Courses ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using only the courses\n",
    "selected_columns = courses_cols\n",
    "print(selected_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Only Characteristics ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using only the user characteristics\n",
    "selected_columns = characteristics_cols\n",
    "print(selected_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Characteristics + Courses ###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_columns = characteristics_cols.to_list() + courses_cols.to_list()\n",
    "print(selected_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only those columns\n",
    "data_selected = data_updated.loc[:,selected_columns]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_error = 0\n",
    "sum_squared_error = 0\n",
    "for course_selected in course_columns: #For each course\n",
    "    print(course_selected)\n",
    "    errors = []\n",
    "    sq_errors = []\n",
    "    if course_selected in data_selected:\n",
    "        X = data_selected.drop(course_selected,axis=1,inplace=False)\n",
    "    else:\n",
    "        X = data_selected\n",
    "    y = data.loc[:,course_selected]\n",
    "    loo = LeaveOneOut()\n",
    "    xgb = XGBRegressor(objective = 'reg:squarederror')\n",
    "    for train_index, test_index in loo.split(X):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "#         print(X_train)\n",
    "        xgb.fit(X_train,y_train)\n",
    "        predictions = xgb.predict(X_test)\n",
    "        errors.append(mean_absolute_error(y_test,predictions))\n",
    "        sq_errors.append(mean_squared_error(y_test,predictions))\n",
    "    \n",
    "    sum_error += np.mean(errors)\n",
    "    sum_squared_error += np.mean(sq_errors)**(1/2)\n",
    "    print(\"MAE:\" + str(np.mean(errors)))\n",
    "    print(\"RMSE:\" + str((np.mean(sq_errors))**(1/2)))\n",
    "\n",
    "print(\"Mean MAE:\" + str( sum_error / (len(course_columns))))\n",
    "print(\"Mean RMSE:\" + str( sum_squared_error / (len(course_columns))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Corellation Table ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "corrmat = data_selected.corr(method=\"pearson\")\n",
    "top_corr_features = corrmat.index\n",
    "plt.figure(figsize=(35, 35))\n",
    "g = sns.heatmap(data_selected[top_corr_features].corr(), annot=True, cmap=\"RdYlGn\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Persistence ##  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "for prediction_course in course_columns:\n",
    "    data_persistence_selected = data_selected[data_selected[prediction_course] >= 0]\n",
    "    X = data_persistence_selected.drop(prediction_course,axis=1,inplace=False)\n",
    "    y = data_persistence_selected.loc[:,prediction_course]\n",
    "    xgb_model = XGBRegressor(objective = 'reg:squarederror')\n",
    "    xgb_model.fit(X,y)\n",
    "    pickle.dump(xgb_model, open(\"models/version2/\" + prediction_course +\".dat\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model.get_booster().feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2.7.15 64-bit ('python2': conda)",
   "name": "python2715jvsc74a57bd00588b3fab998231350a7ac74055f95257dc9abc20cc1aaf9045b727a7004861e"
  },
  "language_info": {
   "name": "python",
   "version": ""
  },
  "metadata": {
   "interpreter": {
    "hash": "0588b3fab998231350a7ac74055f95257dc9abc20cc1aaf9045b727a7004861e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}